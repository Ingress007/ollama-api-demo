# Ollama API Demo

This project demonstrates how to use the Ollama API to interact with local LLM models like qwen3:8b.

## Prerequisites

1. Ollama installed on your system
2. qwen3:8b model pulled locally (`ollama pull qwen3:8b`)

## Installation

```bash
pip install -r requirements.txt
```

## Usage

### Python Examples

1. Run the REST API example:
   ```bash
   python ollama_rest_api.py
   ```

2. Run the Ollama Python client example:
   ```bash
   python ollama_client.py
   ```

### JavaScript Example

1. Run the Node.js example:
   ```bash
   node ollama_js_example.js
   ```